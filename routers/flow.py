from fastapi import APIRouter, HTTPException, Depends, Request
from pydantic import BaseModel
from typing import Optional, List, Dict, Any
from enum import Enum
import uuid
import json
import time
import logging
from datetime import datetime

from services.openai_service import OpenAIService
from services.r2_service import R2Service
from models.api_models import LanguageCode, LearnWord

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

router = APIRouter()

class ConversationStage(str, Enum):
    EMOTION_SELECTION = "emotion_selection"
    STARTER = "starter"
    PROMPT_CAUSE = "prompt_cause"
    USER_ANSWER = "user_answer"
    PARAPHRASE = "paraphrase"
    EMPATHY_VOCAB = "empathy_vocab"
    USER_REPEAT = "user_repeat"
    FINISHER = "finisher"
    COMPLETED = "completed"

class FlowAction(str, Enum):
    PICK_EMOTION = "pick_emotion"
    NEXT_STAGE = "next_stage"
    VOICE_INPUT = "voice_input"
    RESTART = "restart"

class FlowChatRequest(BaseModel):
    session_id: Optional[str] = None
    action: FlowAction
    user_input: Optional[str] = None
    emotion: Optional[str] = None
    from_lang: LanguageCode = LanguageCode.KOREAN
    to_lang: LanguageCode = LanguageCode.ENGLISH

class FlowChatResponse(BaseModel):
    session_id: str
    stage: ConversationStage
    response_text: str
    audio_url: Optional[str] = None
    target_words: Optional[List[LearnWord]] = None
    stt_feedback: Optional[Dict[str, Any]] = None
    completed: bool = False
    next_action: Optional[str] = None

class ConversationSession:
    def __init__(self, session_id: str, emotion: str, from_lang: str, to_lang: str):
        self.session_id = session_id
        self.emotion = emotion
        self.from_lang = from_lang
        self.to_lang = to_lang
        self.stage = ConversationStage.STARTER
        self.learned_expressions = []  # LearnWord ê°ì²´ë“¤ì„ ì €ì¥
        self.user_answers = []
        self.user_input_count = 0  # ì‚¬ìš©ì ìŒì„± ì…ë ¥ íšŸìˆ˜ ì¹´ìš´í„°
        self.created_at = datetime.now()
        self.updated_at = datetime.now()

# ë©”ëª¨ë¦¬ ê¸°ë°˜ ì„¸ì…˜ ì €ì¥ì†Œ (í”„ë¡œë•ì…˜ì—ì„œëŠ” Redisë‚˜ DB ì‚¬ìš©)
sessions: Dict[str, ConversationSession] = {}

# ê°ì •ë³„ êµìœ¡ í‘œí˜„ ì •ì˜ (ê°€ë¥´ì³ì£¼ë ¤ëŠ” í‘œí˜„)
EMOTION_TEACHING_EXPRESSIONS = {
    "happy": [
        {"word": "I'm over the moon", "meaning": "ì •ë§ ê¸°ì©ë‹ˆë‹¤", "pronunciation": "ì•„ì„ ì˜¤ë²„ ë” ë¬¸"},
        {"word": "I'm on cloud nine", "meaning": "êµ¬ë¦„ ìœ„ì— ìˆëŠ” ê²ƒ ê°™ì´ ê¸°ë»ìš”", "pronunciation": "ì•„ì„ ì˜¨ í´ë¼ìš°ë“œ ë‚˜ì¸"},
        {"word": "I'm thrilled", "meaning": "ë„ˆë¬´ ì‹ ë‚˜ìš”", "pronunciation": "ì•„ì„ ì“°ë¦´ë“œ"}
    ],
    "sad": [
        {"word": "I'm feeling down", "meaning": "ê¸°ë¶„ì´ ìš°ìš¸í•´ìš”", "pronunciation": "ì•„ì„ í•„ë§ ë‹¤ìš´"},
        {"word": "I'm heartbroken", "meaning": "ë§ˆìŒì´ ì•„í”•ë‹ˆë‹¤", "pronunciation": "ì•„ì„ í•˜íŠ¸ë¸Œë¡œí°"},
        {"word": "I'm devastated", "meaning": "ë„ˆë¬´ ìƒì‹¬í–ˆì–´ìš”", "pronunciation": "ì•„ì„ ë°ë°”ìŠ¤í…Œì´í‹°ë“œ"}
    ],
    "angry": [
        {"word": "I'm furious", "meaning": "í™”ê°€ ë§ì´ ë‚©ë‹ˆë‹¤", "pronunciation": "ì•„ì„ í“¨ë¦¬ì–´ìŠ¤"},
        {"word": "I'm livid", "meaning": "ë„ˆë¬´ í™”ê°€ ë‚˜ìš”", "pronunciation": "ì•„ì„ ë¦¬ë¹„ë“œ"},
        {"word": "I'm outraged", "meaning": "ë¶„ë…¸í•˜ê³  ìˆì–´ìš”", "pronunciation": "ì•„ì„ ì•„ì›ƒë ˆì´ì§€ë“œ"}
    ],
    "scared": [
        {"word": "I'm terrified", "meaning": "ë„ˆë¬´ ë¬´ì„œì›Œìš”", "pronunciation": "ì•„ì„ í…Œë¦¬íŒŒì´ë“œ"},
        {"word": "I'm petrified", "meaning": "ë¬´ì„œì›Œì„œ ì–¼ì–´ë¶™ì—ˆì–´ìš”", "pronunciation": "ì•„ì„ í˜íŠ¸ë¦¬íŒŒì´ë“œ"},
        {"word": "I'm shaking with fear", "meaning": "ë¬´ì„œì›Œì„œ ë–¨ê³  ìˆì–´ìš”", "pronunciation": "ì•„ì„ ì‰ì´í‚¹ ìœ„ë“œ í”¼ì–´"}
    ],
    "shy": [
        {"word": "I'm bashful", "meaning": "ë¶€ë„ëŸ¬ì›Œìš”", "pronunciation": "ì•„ì„ ë°°ì‰¬í’€"},
        {"word": "I'm timid", "meaning": "ì†Œì‹¬í•´ìš”", "pronunciation": "ì•„ì„ í‹°ë¯¸ë“œ"},
        {"word": "I'm self-conscious", "meaning": "ì˜ì‹í•˜ê³  ìˆì–´ìš”", "pronunciation": "ì•„ì„ ì…€í”„ ì»¨ì…”ìŠ¤"}
    ],
    "sleepy": [
        {"word": "I'm drowsy", "meaning": "ì¡¸ë ¤ìš”", "pronunciation": "ì•„ì„ ë“œë¼ìš°ì§€"},
        {"word": "I'm exhausted", "meaning": "ì§€ì³ìˆì–´ìš”", "pronunciation": "ì•„ì„ ì´ê·¸ì¡°ìŠ¤í‹°ë“œ"},
        {"word": "I'm worn out", "meaning": "ê¸°ì§„ë§¥ì§„í•´ìš”", "pronunciation": "ì•„ì„ ì› ì•„ì›ƒ"}
    ],
    "upset": [
        {"word": "I'm distressed", "meaning": "ê´´ë¡œì›Œìš”", "pronunciation": "ì•„ì„ ë””ìŠ¤íŠ¸ë ˆìŠ¤ë“œ"},
        {"word": "I'm troubled", "meaning": "ê³ ë¯¼ì´ ìˆì–´ìš”", "pronunciation": "ì•„ì„ íŠ¸ëŸ¬ë¸”ë“œ"},
        {"word": "I'm bothered", "meaning": "ì‹ ê²½ì“°ì—¬ìš”", "pronunciation": "ì•„ì„ ë°”ë”ë“œ"}
    ],
    "confused": [
        {"word": "I'm bewildered", "meaning": "ë‹¹í™©ìŠ¤ëŸ¬ì›Œìš”", "pronunciation": "ì•„ì„ ë¹„ì™€ì¼ë”ë“œ"},
        {"word": "I'm perplexed", "meaning": "í˜¼ë€ìŠ¤ëŸ¬ì›Œìš”", "pronunciation": "ì•„ì„ í¼í”Œë ‰ìŠ¤ë“œ"},
        {"word": "I'm puzzled", "meaning": "ì˜ì•„í•´ìš”", "pronunciation": "ì•„ì„ í¼ì¦ë“œ"}
    ],
    "bored": [
        {"word": "I'm uninterested", "meaning": "í¥ë¯¸ê°€ ì—†ì–´ìš”", "pronunciation": "ì•„ì„ ì–¸ì¸í„°ë ˆìŠ¤í‹°ë“œ"},
        {"word": "I'm restless", "meaning": "ì•ˆì ˆë¶€ì ˆëª»í•´ìš”", "pronunciation": "ì•„ì„ ë ˆìŠ¤íŠ¸ë¦¬ìŠ¤"},
        {"word": "I'm disengaged", "meaning": "ê´€ì‹¬ì´ ì—†ì–´ìš”", "pronunciation": "ì•„ì„ ë””ìŠ¤ì¸ê²Œì´ì§€ë“œ"}
    ],
    "love": [
        {"word": "I'm smitten", "meaning": "í‘¹ ë¹ ì¡Œì–´ìš”", "pronunciation": "ì•„ì„ ìŠ¤ë¯¸íŠ¼"},
        {"word": "I'm infatuated", "meaning": "ë°˜í•´ë²„ë ¸ì–´ìš”", "pronunciation": "ì•„ì„ ì¸íŒ¨ì¸„ì—ì´í‹°ë“œ"},
        {"word": "I'm head over heels", "meaning": "ì™„ì „íˆ ë¹ ì ¸ìˆì–´ìš”", "pronunciation": "ì•„ì„ í—¤ë“œ ì˜¤ë²„ íìŠ¤"}
    ],
    "proud": [
        {"word": "I'm accomplished", "meaning": "ì„±ì·¨ê°ì„ ëŠê»´ìš”", "pronunciation": "ì•„ì„ ì–´ì»´í”Œë¦¬ì‰¬ë“œ"},
        {"word": "I'm triumphant", "meaning": "ìŠ¹ë¦¬ê°ì„ ëŠê»´ìš”", "pronunciation": "ì•„ì„ íŠ¸ë¼ì´ì—„í€íŠ¸"},
        {"word": "I'm elated", "meaning": "ìš°ì­í•´ìš”", "pronunciation": "ì•„ì„ ì¼ë ˆì´í‹°ë“œ"}
    ],
    "nervous": [
        {"word": "I'm anxious", "meaning": "ë¶ˆì•ˆí•´ìš”", "pronunciation": "ì•„ì„ ì•µì‹œì–´ìŠ¤"},
        {"word": "I'm jittery", "meaning": "ì´ˆì¡°í•´ìš”", "pronunciation": "ì•„ì„ ì§€í„°ë¦¬"},
        {"word": "I'm apprehensive", "meaning": "ê±±ì •ë¼ìš”", "pronunciation": "ì•„ì„ ì• í”„ë¦¬í—¨ì‹œë¸Œ"}
    ]
}

def _log_request(request: Request, flow_request: FlowChatRequest, start_time: float):
    """ìš”ì²­ ë¡œê¹… (ìš”ì•½)"""
    client_ip = request.client.host if request.client else "unknown"
    user_agent = request.headers.get("user-agent", "unknown")
    
    # ë¯¼ê°í•œ ì •ë³´ ë§ˆìŠ¤í‚¹
    masked_request = flow_request.dict()
    if masked_request.get("user_input"):
        masked_request["user_input"] = f"{masked_request['user_input'][:20]}..." if len(masked_request["user_input"]) > 20 else masked_request["user_input"]
    
    logger.info(f"[FLOW_API_REQUEST] IP: {client_ip} | User-Agent: {user_agent[:100]} | Request: {masked_request}")

def _log_request_full(request: Request, flow_request: FlowChatRequest, start_time: float):
    """ìš”ì²­ ì „ì²´ ë¡œê¹… (ìƒì„¸)"""
    client_ip = request.client.host if request.client else "unknown"
    user_agent = request.headers.get("user-agent", "unknown")
    
    # ì „ì²´ ìš”ì²­ ë°ì´í„° ë¡œê¹…
    full_request = flow_request.dict()
    
    logger.info(f"[FLOW_API_REQUEST_FULL] ===== REQUEST START =====")
    logger.info(f"[FLOW_API_REQUEST_FULL] IP: {client_ip}")
    logger.info(f"[FLOW_API_REQUEST_FULL] User-Agent: {user_agent}")
    logger.info(f"[FLOW_API_REQUEST_FULL] Headers: {dict(request.headers)}")
    logger.info(f"[FLOW_API_REQUEST_FULL] Method: {request.method}")
    logger.info(f"[FLOW_API_REQUEST_FULL] URL: {request.url}")
    logger.info(f"[FLOW_API_REQUEST_FULL] Request Body: {json.dumps(full_request, ensure_ascii=False, indent=2)}")
    logger.info(f"[FLOW_API_REQUEST_FULL] ===== REQUEST END =====")

def _log_response(flow_request: FlowChatRequest, response: FlowChatResponse, start_time: float, status_code: int = 200):
    """ì‘ë‹µ ë¡œê¹… (ìš”ì•½)"""
    elapsed_time = time.time() - start_time
    
    # ì‘ë‹µ ë°ì´í„° ë§ˆìŠ¤í‚¹
    masked_response = response.dict()
    if masked_response.get("response_text"):
        masked_response["response_text"] = f"{masked_response['response_text'][:50]}..." if len(masked_response["response_text"]) > 50 else masked_response["response_text"]
    
    logger.info(f"[FLOW_API_RESPONSE] Action: {flow_request.action} | Session: {response.session_id} | Stage: {response.stage} | Status: {status_code} | Time: {elapsed_time:.3f}s | Response: {masked_response}")

def _log_response_full(flow_request: FlowChatRequest, response: FlowChatResponse, start_time: float, status_code: int = 200):
    """ì‘ë‹µ ì „ì²´ ë¡œê¹… (ìƒì„¸)"""
    elapsed_time = time.time() - start_time
    
    # ì „ì²´ ì‘ë‹µ ë°ì´í„° ë¡œê¹…
    full_response = response.dict()
    
    logger.info(f"[FLOW_API_RESPONSE_FULL] ===== RESPONSE START =====")
    logger.info(f"[FLOW_API_RESPONSE_FULL] Action: {flow_request.action}")
    logger.info(f"[FLOW_API_RESPONSE_FULL] Session: {response.session_id}")
    logger.info(f"[FLOW_API_RESPONSE_FULL] Stage: {response.stage}")
    logger.info(f"[FLOW_API_RESPONSE_FULL] Status Code: {status_code}")
    logger.info(f"[FLOW_API_RESPONSE_FULL] Elapsed Time: {elapsed_time:.3f}s")
    logger.info(f"[FLOW_API_RESPONSE_FULL] Response Body: {json.dumps(full_response, ensure_ascii=False, indent=2, default=str)}")
    logger.info(f"[FLOW_API_RESPONSE_FULL] ===== RESPONSE END =====")

def _log_session_activity(session_id: str, activity: str, details: Dict[str, Any] = None):
    """ì„¸ì…˜ í™œë™ ë¡œê¹…"""
    log_data = {
        "session_id": session_id,
        "activity": activity,
        "timestamp": datetime.now().isoformat()
    }
    if details:
        log_data.update(details)
    
    logger.info(f"[FLOW_SESSION_ACTIVITY] {log_data}")

def _log_error(error: Exception, flow_request: FlowChatRequest, start_time: float):
    """ì—ëŸ¬ ë¡œê¹… (ìƒì„¸)"""
    elapsed_time = time.time() - start_time
    
    # ìš”ì•½ ì—ëŸ¬ ë¡œê¹…
    logger.error(f"[FLOW_API_ERROR] Action: {flow_request.action} | Session: {flow_request.session_id} | Error: {str(error)} | Time: {elapsed_time:.3f}s")
    
    # ìƒì„¸ ì—ëŸ¬ ë¡œê¹…
    logger.error(f"[FLOW_API_ERROR_FULL] ===== ERROR START =====")
    logger.error(f"[FLOW_API_ERROR_FULL] Action: {flow_request.action}")
    logger.error(f"[FLOW_API_ERROR_FULL] Session: {flow_request.session_id}")
    logger.error(f"[FLOW_API_ERROR_FULL] Error Type: {type(error).__name__}")
    logger.error(f"[FLOW_API_ERROR_FULL] Error Message: {str(error)}")
    logger.error(f"[FLOW_API_ERROR_FULL] Elapsed Time: {elapsed_time:.3f}s")
    logger.error(f"[FLOW_API_ERROR_FULL] Request Data: {json.dumps(flow_request.dict(), ensure_ascii=False, indent=2)}")
    logger.error(f"[FLOW_API_ERROR_FULL] ===== ERROR END =====", exc_info=True)

def get_openai_service():
    return OpenAIService()

@router.post("/flow-chat", response_model=FlowChatResponse)
async def flow_chat(
    request: FlowChatRequest,
    http_request: Request,
    openai_service: OpenAIService = Depends(get_openai_service)
):
    """
    Flow-Chat API: ë°˜ë³µ ëŒ€í™” ê¸°ë°˜ ì–¸ì–´í•™ìŠµ ì‹œìŠ¤í…œ
    
    íë¦„:
    1. starter -> voice_input (ì‚¬ìš©ì ìŒì„± ë‹µë³€ ëŒ€ê¸°)
    2. paraphrase -> next_stage (ë°˜ì‘ -> paraphrasing -> ìƒˆë¡œìš´ í‘œí˜„ ì•Œë ¤ì£¼ê¸° -> ê´€ë ¨ëœ ì§ˆë¬¸ í•˜ê¸°)
    3. ìœ„ ê³¼ì •ì„ ë°˜ë³µ (7íšŒ user_inputê¹Œì§€)
    4. finisher (7íšŒì§¸ user_input í›„ ëŒ€í™” ì™„ë£Œ)
    """
    
    start_time = time.time()
    
    # ìš”ì²­ ë¡œê¹… (ìš”ì•½ + ìƒì„¸)
    _log_request(http_request, request, start_time)
    _log_request_full(http_request, request, start_time)
    
    try:
        # ìƒˆ ì„¸ì…˜ ìƒì„± ë˜ëŠ” ê¸°ì¡´ ì„¸ì…˜ ë¡œë“œ
        if request.action == FlowAction.PICK_EMOTION:
            if not request.emotion:
                logger.warning(f"[FLOW_API_VALIDATION] Missing emotion for pick_emotion action")
                raise HTTPException(status_code=400, detail="Emotion is required for pick_emotion action")
            
            session_id = str(uuid.uuid4())
            session = ConversationSession(
                session_id=session_id,
                emotion=request.emotion.lower(),
                from_lang=request.from_lang.value,
                to_lang=request.to_lang.value
            )
            sessions[session_id] = session
            
            # ì„¸ì…˜ ìƒì„± ë¡œê¹…
            _log_session_activity(session_id, "SESSION_CREATED", {
                "emotion": request.emotion.lower(),
                "from_lang": request.from_lang.value,
                "to_lang": request.to_lang.value
            })
            
            # OpenAIë¡œ ì‹œì‘ ì‘ë‹µ ìƒì„± (TTS í¬í•¨)
            combined_response, audio_url = await _generate_openai_response_with_tts(session, ConversationStage.STARTER, openai_service)
            
            response = FlowChatResponse(
                session_id=session_id,
                stage=ConversationStage.STARTER,
                response_text=combined_response,
                audio_url=audio_url,  # ìƒì„±ëœ TTS ì˜¤ë””ì˜¤ URL ì‚¬ìš©
                completed=False,
                next_action="Please tell me about what made you feel this way using voice input"
            )
            
            # ì‘ë‹µ ë¡œê¹… (ìš”ì•½ + ìƒì„¸)
            _log_response(request, response, start_time)
            _log_response_full(request, response, start_time)
            
            return response
        
        # ê¸°ì¡´ ì„¸ì…˜ ì²˜ë¦¬
        if not request.session_id or request.session_id not in sessions:
            logger.warning(f"[FLOW_API_VALIDATION] Session not found: {request.session_id}")
            raise HTTPException(status_code=404, detail="Session not found")
        
        session = sessions[request.session_id]
        session.updated_at = datetime.now()
        
        # ì„¸ì…˜ ì ‘ê·¼ ë¡œê¹…
        _log_session_activity(request.session_id, "SESSION_ACCESSED", {
            "current_stage": session.stage,
            "emotion": session.emotion,
            "action": request.action
        })
        
        if request.action == FlowAction.NEXT_STAGE:
            response = await _handle_next_stage(session, openai_service)
            
        elif request.action == FlowAction.VOICE_INPUT:
            if not request.user_input:
                logger.warning(f"[FLOW_API_VALIDATION] Missing user_input for voice_input action in session {request.session_id}")
                raise HTTPException(status_code=400, detail="User input is required for voice_input action")
            
            response = await _handle_voice_input(session, request.user_input, openai_service)
            
        elif request.action == FlowAction.RESTART:
            session.stage = ConversationStage.STARTER
            session.user_answers = []
            session.learned_expressions = []
            session.user_input_count = 0
            
            # ì„¸ì…˜ ì¬ì‹œì‘ ë¡œê¹…
            _log_session_activity(request.session_id, "SESSION_RESTARTED", {
                "emotion": session.emotion
            })
            
            # OpenAIë¡œ ì¬ì‹œì‘ ì‘ë‹µ ìƒì„± (TTS í¬í•¨)
            response_text, audio_url = await _generate_openai_response_with_tts(session, ConversationStage.RESTART, openai_service)
            
            response = FlowChatResponse(
                session_id=session.session_id,
                stage=ConversationStage.STARTER,
                response_text=response_text,
                audio_url=audio_url,  # ìƒì„±ëœ TTS ì˜¤ë””ì˜¤ URL ì‚¬ìš©
                completed=False,
                next_action="Please tell me about what made you feel this way using voice input"
            )
        
        else:
            logger.warning(f"[FLOW_API_VALIDATION] Invalid action: {request.action} for session {request.session_id}")
            raise HTTPException(status_code=400, detail="Invalid action")
        
        # ì‘ë‹µ ë¡œê¹… (ìš”ì•½ + ìƒì„¸)
        _log_response(request, response, start_time)
        _log_response_full(request, response, start_time)
        
        return response
            
    except HTTPException as e:
        # HTTP ì˜ˆì™¸ ë¡œê¹…
        _log_error(e, request, start_time)
        raise
    except Exception as e:
        # ì¼ë°˜ ì˜ˆì™¸ ë¡œê¹…
        _log_error(e, request, start_time)
        raise HTTPException(status_code=500, detail=f"Internal server error: {str(e)}")

async def _handle_next_stage(session: ConversationSession, openai_service: OpenAIService) -> FlowChatResponse:
    """ë‹¤ìŒ ë‹¨ê³„ë¡œ ì§„í–‰"""
    
    logger.info(f"[FLOW_STAGE_TRANSITION] Session: {session.session_id} | From: {session.stage} | Emotion: {session.emotion} | Input Count: {session.user_input_count}/7")
    
    # STARTER ë‹¨ê³„ì—ì„œëŠ” voice_inputìœ¼ë¡œ ì§ì ‘ ì§„í–‰ (Mixed language)
    if session.stage == ConversationStage.STARTER:
        # Mixed languageë¡œ ì‘ë‹µ ìƒì„±
        response_text = f"{session.emotion} ê°ì •ê³¼ ê´€ë ¨ëœ expressionsë¥¼ ë°°ì›Œë´ìš”! ìŒì„±ìœ¼ë¡œ ìµœê·¼ì— {session.emotion}ì„ ëŠë‚€ ê²½í—˜ì„ ì´ì•¼ê¸°í•´ì£¼ì„¸ìš”."
        next_action = "ê°ì •ì— ëŒ€í•´ ìŒì„±ìœ¼ë¡œ ì´ì•¼ê¸°í•´ì£¼ì„¸ìš”"
        
        # Apply TTS to response_text (Mixed language so English is default)
        audio_url = None
        try:
            tts_language = "English"  # Mixed languageëŠ” ì£¼ë¡œ ì˜ì–´ ê¸°ë°˜
            audio_url, duration = await openai_service.text_to_speech(response_text, tts_language)
            logger.info(f"[FLOW_STARTER_TTS_SUCCESS] Session: {session.session_id} | Audio URL: {audio_url} | Duration: {duration:.2f}s")
        except Exception as tts_error:
            logger.error(f"[FLOW_STARTER_TTS_ERROR] Session: {session.session_id} | TTS failed: {str(tts_error)}")
        
        return FlowChatResponse(
            session_id=session.session_id,
            stage=ConversationStage.STARTER,
            response_text=response_text,
            audio_url=audio_url,  # ìƒì„±ëœ TTS ì˜¤ë””ì˜¤ URL ì‚¬ìš©
            completed=False,
            next_action=next_action
        )
    
    elif session.stage == ConversationStage.PARAPHRASE:
        # Paraphrase ë‹¨ê³„ì—ì„œ í•™ìŠµëœ í‘œí˜„ë“¤ì„ ë³´ì—¬ì£¼ê³  ë”°ë¼í•´ë³´ë¼ê³  ë§í•˜ê¸°
        
        # í•™ìŠµëœ í‘œí˜„ë“¤ í‘œì‹œ
        if session.learned_expressions:
            expressions_text = ""
            for i, expr in enumerate(session.learned_expressions, 1):
                expressions_text += f"{i}. {expr.word} - {expr.meaning} ({expr.pronunciation})\n"
                if expr.example:
                    expressions_text += f"   Example: {expr.example}\n"
        else:
            expressions_text = "ìƒˆë¡œìš´ expressionsê°€ ì—†ì–´ìš”."
        
        # ë”°ë¼í•´ë³´ë¼ê³  ë§í•˜ê¸° (Mixed languageë¡œ)
        response_text = f"ì¢‹ì•„ìš”! ì´ëŸ° expressionsë“¤ì„ ë°°ì›Œë´ìš”:\n\n{expressions_text}\nìœ„ì˜ expressionsë“¤ì„ ë”°ë¼í•´ë³´ì„¸ìš”! í° ì†Œë¦¬ë¡œ ë§í•´ë´ìš” ğŸ˜Š"
        next_action = "ë”°ë¼í•´ë³´ì‹  í›„ ìŒì„±ìœ¼ë¡œ ë‹¤ìŒ ì´ì•¼ê¸°ë¥¼ ë“¤ë ¤ì£¼ì„¸ìš”"
        
        # ë‹¤ì‹œ voice_inputì„ ë°›ê¸° ìœ„í•´ stageëŠ” paraphraseë¡œ ìœ ì§€
        session.stage = ConversationStage.PARAPHRASE
        
        _log_session_activity(session.session_id, "EXPRESSIONS_FOR_REPEAT", {
            "emotion": session.emotion,
            "user_input_count": session.user_input_count,
            "learned_expressions": [expr.word for expr in session.learned_expressions],
            "total_expressions": len(session.learned_expressions)
        })
        
        audio_url = None
        try:
            tts_language = "English"  # Mixed language ì£¼ë¡œ ì˜ì–´ ê¸°ë°˜
            audio_url, duration = await openai_service.text_to_speech(response_text, tts_language)
            logger.info(f"[FLOW_NEXT_STAGE_TTS_SUCCESS] Session: {session.session_id} | Audio URL: {audio_url} | Duration: {duration:.2f}s")
        except Exception as tts_error:
            logger.error(f"[FLOW_NEXT_STAGE_TTS_ERROR] Session: {session.session_id} | TTS failed: {str(tts_error)}")
        
        return FlowChatResponse(
            session_id=session.session_id,
            stage=ConversationStage.PARAPHRASE,
            response_text=response_text,
            audio_url=audio_url,  # ìƒì„±ëœ TTS ì˜¤ë””ì˜¤ URL ì‚¬ìš©
            target_words=session.learned_expressions,
            completed=False,
            next_action=next_action
        )
    
    else:
        logger.warning(f"[FLOW_STAGE_ERROR] Cannot proceed to next stage from {session.stage} in session {session.session_id}")
        raise HTTPException(status_code=400, detail="Cannot proceed to next stage from current stage")

async def _handle_voice_input(session: ConversationSession, user_input: str, openai_service: OpenAIService) -> FlowChatResponse:
    """ìŒì„± ì…ë ¥ ì²˜ë¦¬"""
    
    logger.info(f"[FLOW_VOICE_INPUT] Session: {session.session_id} | Stage: {session.stage} | Input: {user_input[:50]}...")
    
    # ì‚¬ìš©ì ì…ë ¥ ì¹´ìš´í„° ì¦ê°€
    session.user_input_count += 1
    session.user_answers.append(user_input)
    
    logger.info(f"[FLOW_USER_INPUT_COUNT] Session: {session.session_id} | Count: {session.user_input_count}/7")
    
    # 7íšŒì§¸ ì…ë ¥ì´ë©´ ëŒ€í™” ì™„ë£Œ
    if session.user_input_count >= 7:
        session.stage = ConversationStage.FINISHER
        
        # OpenAIë¡œ ì™„ë£Œ ì‘ë‹µ ìƒì„± (TTS í¬í•¨)
        response_text, audio_url = await _generate_openai_response_with_tts(session, ConversationStage.FINISHER, openai_service)
        
        _log_session_activity(session.session_id, "CONVERSATION_COMPLETED", {
            "emotion": session.emotion,
            "learned_expressions": [expr.word for expr in session.learned_expressions],
            "user_answers": len(session.user_answers),
            "total_user_inputs": session.user_input_count,
            "final_stage": ConversationStage.FINISHER
        })
        
        completion_action = "Conversation completed! Your learned expressions have been saved."
        
        return FlowChatResponse(
            session_id=session.session_id,
            stage=ConversationStage.FINISHER,
            response_text=response_text,
            audio_url=audio_url,  # ìƒì„±ëœ TTS ì˜¤ë””ì˜¤ URL ì‚¬ìš©
            completed=True,
            next_action=completion_action
        )
    
    # STARTER ë‹¨ê³„ ë˜ëŠ” PARAPHRASE ë‹¨ê³„ì—ì„œ voice_input ì²˜ë¦¬
    if session.stage == ConversationStage.STARTER or session.stage == ConversationStage.PARAPHRASE:
        # Paraphrase ë‹¨ê³„ë¡œ ì´ë™
        session.stage = ConversationStage.PARAPHRASE
        
        # ì–¸ì–´ ì„¤ì • - Mixed language ì‚¬ìš©
        mixed_language = f"Mixed {session.from_lang}-{session.to_lang}"
        user_language = "Korean" if session.from_lang == "korean" else session.from_lang 
        ai_language = "English" if session.to_lang == "english" else session.to_lang
        
        # ë‹¨ìˆœí™”ëœ ë‹¨ì¼ OpenAI í˜¸ì¶œ: ì‘ë‹µê³¼ í•™ìŠµ í‘œí˜„ì„ í•œ ë²ˆì— ìƒì„±
        unified_prompt = f"""
        User said: "{user_input}" (language study topic: {session.emotion})
        Response should be in {mixed_language}
        Response should be 3-4 short sentences. 
        
        Create a response in {mixed_language} with steps:
        - Empathetic reaction to user's feeling (if needed)
        - Introduce related {ai_language} expressions 
        - Paraphrase user's feeling in {ai_language}
        
        Then provide 2 {ai_language} expressions used in your paraphrase response.
        
        Respond in JSON format:
        {{
            "response": "your mixed language response here",
            "learned_expressions": [
                {{"word": "expression", "meaning": "{user_language} meaning", "pronunciation": "pronunciation", "example": "example sentence"}}
            ]
        }}
        """
        
        _log_session_activity(session.session_id, "USER_ANSWER_RECEIVED", {
            "emotion": session.emotion,
            "user_input": user_input,
            "user_input_count": session.user_input_count,
            "answer_count": len(session.user_answers)
        })
        
        try:
            logger.info(f"[FLOW_UNIFIED_REQUEST] Session: {session.session_id} | Generating unified response")
            
            # ë‹¨ì¼ OpenAI í˜¸ì¶œë¡œ ì‘ë‹µê³¼ í‘œí˜„ ìƒì„±
            unified_response = await openai_service.get_chat_completion(
                messages=[{"role": "user", "content": unified_prompt}],
                temperature=0.7,
                response_format={"type": "json_object"}
            )
            unified_content = unified_response.choices[0].message.content.strip()
            
            logger.info(f"[FLOW_UNIFIED_SUCCESS] Session: {session.session_id} | Generated unified response")
            logger.info(f"[FLOW_UNIFIED_CONTENT] Session: {session.session_id} | Response: {unified_content}")
            
            # JSON ì‘ë‹µ íŒŒì‹±
            parsed_response = json.loads(unified_content)
            paraphrase_text = parsed_response.get("response", "")
            learned_expressions_data = parsed_response.get("learned_expressions", [])
            
            # LearnWord ê°ì²´ë“¤ ìƒì„±
            learned_expressions = []
            for expr_data in learned_expressions_data:
                word = expr_data.get("word", "").replace('**', '').replace('##', '').strip()
                meaning = expr_data.get("meaning", "").replace('**', '').replace('##', '').strip()
                pronunciation = expr_data.get("pronunciation", "").replace('**', '').replace('##', '').strip()
                example = expr_data.get("example", "").replace('**', '').replace('##', '').strip()
                
                if word:  # ë¹ˆ ë‹¨ì–´ ì œì™¸
                    learn_word = LearnWord(
                        word=word,
                        meaning=meaning,
                        pronunciation=pronunciation,
                        example=example
                    )
                    learned_expressions.append(learn_word)
            
            # ì„¸ì…˜ì— ì €ì¥
            session.learned_expressions = learned_expressions
            
            logger.info(f"[FLOW_EXPRESSION_GENERATION] Session: {session.session_id} | Generated {len(learned_expressions)} expressions")
            
        except (json.JSONDecodeError, Exception) as e:
            logger.error(f"[FLOW_UNIFIED_ERROR] Session: {session.session_id} | Unified call failed: {str(e)}")
            
            # ê°„ë‹¨í•œ fallback ì²˜ë¦¬
            paraphrase_text = f"ì•„, {session.emotion} ê°ì •ì´ì‹œêµ°ìš”! ì •ë§ {user_input}í•˜ì…¨ì„ ë•Œ ê·¸ëŸ° ê¸°ë¶„ì´ ë“¤ì—ˆì„ ê²ƒ ê°™ì•„ìš”. 'I feel {session.emotion}'ë¼ê³  ë§í•  ìˆ˜ ìˆì–´ìš”. ë‹¤ë¥¸ ê²½í—˜ë„ ë” ì–˜ê¸°í•´ì£¼ì„¸ìš”!"
            
            # ê¸°ë³¸ í•™ìŠµ í‘œí˜„ ìƒì„±
            learned_expressions = [
                LearnWord(
                    word=f"I feel {session.emotion}",
                    meaning=f"ë‚˜ëŠ” {session.emotion}ì„ ëŠê»´ìš”",
                    pronunciation=f"ì•„ì´ í•„ {session.emotion}",
                    example=f"I feel {session.emotion} when good things happen."
                ),
                LearnWord(
                    word="when",
                    meaning="~í•  ë•Œ",
                    pronunciation="ì›¬",
                    example="I feel happy when I see my friends."
                ),
                LearnWord(
                    word="experience",
                    meaning="ê²½í—˜",
                    pronunciation="ìµìŠ¤í”¼ë¦¬ì–¸ìŠ¤",
                    example="Tell me about your experience."
                )
            ]
            session.learned_expressions = learned_expressions
        
        # TTS ì²˜ë¦¬
        audio_url = None
        try:
            tts_language = "English"  # Mixed languageëŠ” ì£¼ë¡œ ì˜ì–´ ê¸°ë°˜
            audio_url, duration = await openai_service.text_to_speech(paraphrase_text, tts_language)
            logger.info(f"[FLOW_PARAPHRASE_TTS_SUCCESS] Session: {session.session_id} | Audio URL: {audio_url} | Duration: {duration:.2f}s")
        except Exception as tts_error:
            logger.error(f"[FLOW_PARAPHRASE_TTS_ERROR] Session: {session.session_id} | TTS failed: {str(tts_error)}")
        
        voice_input_action = "Use next_stage to learn new expressions and get next question"
        
        return FlowChatResponse(
            session_id=session.session_id,
            stage=ConversationStage.PARAPHRASE,
            response_text=paraphrase_text,
            audio_url=audio_url,
            target_words=session.learned_expressions,
            completed=False,
            next_action=voice_input_action
        )
    
    else:
        logger.warning(f"[FLOW_VOICE_INPUT_ERROR] Voice input not expected at stage {session.stage} in session {session.session_id}")
        raise HTTPException(status_code=400, detail="Voice input not expected at current stage")

@router.get("/flow-chat/session/{session_id}")
async def get_session_info(session_id: str, request: Request):
    """ì„¸ì…˜ ì •ë³´ ì¡°íšŒ"""
    start_time = time.time()
    
    # ìš”ì²­ ë¡œê¹…
    client_ip = request.client.host if request.client else "unknown"
    user_agent = request.headers.get("user-agent", "unknown")
    
    logger.info(f"[FLOW_SESSION_INFO_REQUEST] Session: {session_id} | IP: {client_ip}")
    logger.info(f"[FLOW_SESSION_INFO_REQUEST_FULL] ===== GET SESSION REQUEST START =====")
    logger.info(f"[FLOW_SESSION_INFO_REQUEST_FULL] Session ID: {session_id}")
    logger.info(f"[FLOW_SESSION_INFO_REQUEST_FULL] IP: {client_ip}")
    logger.info(f"[FLOW_SESSION_INFO_REQUEST_FULL] User-Agent: {user_agent}")
    logger.info(f"[FLOW_SESSION_INFO_REQUEST_FULL] Headers: {dict(request.headers)}")
    logger.info(f"[FLOW_SESSION_INFO_REQUEST_FULL] Method: {request.method}")
    logger.info(f"[FLOW_SESSION_INFO_REQUEST_FULL] URL: {request.url}")
    logger.info(f"[FLOW_SESSION_INFO_REQUEST_FULL] ===== GET SESSION REQUEST END =====")
    
    if session_id not in sessions:
        logger.warning(f"[FLOW_SESSION_NOT_FOUND] Session: {session_id}")
        raise HTTPException(status_code=404, detail="Session not found")
    
    session = sessions[session_id]
    
    response_data = {
        "session_id": session.session_id,
        "emotion": session.emotion,
        "stage": session.stage,
        "learned_expressions": [expr.dict() for expr in session.learned_expressions],
        "user_answers": session.user_answers,
        "user_input_count": session.user_input_count,
        "max_inputs": 7,
        "created_at": session.created_at,
        "updated_at": session.updated_at
    }
    
    elapsed_time = time.time() - start_time
    
    # ì‘ë‹µ ë¡œê¹… (ìš”ì•½ + ìƒì„¸)
    logger.info(f"[FLOW_SESSION_INFO_RESPONSE] Session: {session_id} | Time: {elapsed_time:.3f}s")
    logger.info(f"[FLOW_SESSION_INFO_RESPONSE_FULL] ===== GET SESSION RESPONSE START =====")
    logger.info(f"[FLOW_SESSION_INFO_RESPONSE_FULL] Session: {session_id}")
    logger.info(f"[FLOW_SESSION_INFO_RESPONSE_FULL] Status Code: 200")
    logger.info(f"[FLOW_SESSION_INFO_RESPONSE_FULL] Elapsed Time: {elapsed_time:.3f}s")
    logger.info(f"[FLOW_SESSION_INFO_RESPONSE_FULL] Response Body: {json.dumps(response_data, ensure_ascii=False, indent=2, default=str)}")
    logger.info(f"[FLOW_SESSION_INFO_RESPONSE_FULL] ===== GET SESSION RESPONSE END =====")
    
    return response_data

@router.delete("/flow-chat/session/{session_id}")
async def delete_session(session_id: str, request: Request):
    """ì„¸ì…˜ ì‚­ì œ"""
    start_time = time.time()
    
    # ìš”ì²­ ë¡œê¹…
    client_ip = request.client.host if request.client else "unknown"
    user_agent = request.headers.get("user-agent", "unknown")
    
    logger.info(f"[FLOW_SESSION_DELETE_REQUEST] Session: {session_id} | IP: {client_ip}")
    logger.info(f"[FLOW_SESSION_DELETE_REQUEST_FULL] ===== DELETE SESSION REQUEST START =====")
    logger.info(f"[FLOW_SESSION_DELETE_REQUEST_FULL] Session ID: {session_id}")
    logger.info(f"[FLOW_SESSION_DELETE_REQUEST_FULL] IP: {client_ip}")
    logger.info(f"[FLOW_SESSION_DELETE_REQUEST_FULL] User-Agent: {user_agent}")
    logger.info(f"[FLOW_SESSION_DELETE_REQUEST_FULL] Headers: {dict(request.headers)}")
    logger.info(f"[FLOW_SESSION_DELETE_REQUEST_FULL] Method: {request.method}")
    logger.info(f"[FLOW_SESSION_DELETE_REQUEST_FULL] URL: {request.url}")
    logger.info(f"[FLOW_SESSION_DELETE_REQUEST_FULL] ===== DELETE SESSION REQUEST END =====")
    
    if session_id not in sessions:
        logger.warning(f"[FLOW_SESSION_DELETE_NOT_FOUND] Session: {session_id}")
        raise HTTPException(status_code=404, detail="Session not found")
    
    # ì„¸ì…˜ ì‚­ì œ ì „ ì •ë³´ ë¡œê¹…
    session = sessions[session_id]
    _log_session_activity(session_id, "SESSION_DELETED", {
        "emotion": session.emotion,
        "stage": session.stage,
        "learned_expressions": [expr.word for expr in session.learned_expressions],
        "user_answers": len(session.user_answers),
        "user_input_count": session.user_input_count,
        "duration": (datetime.now() - session.created_at).total_seconds()
    })
    
    del sessions[session_id]
    
    response_data = {"message": "Session deleted successfully"}
    elapsed_time = time.time() - start_time
    
    # ì‘ë‹µ ë¡œê¹… (ìš”ì•½ + ìƒì„¸)
    logger.info(f"[FLOW_SESSION_DELETE_RESPONSE] Session: {session_id} | Time: {elapsed_time:.3f}s")
    logger.info(f"[FLOW_SESSION_DELETE_RESPONSE_FULL] ===== DELETE SESSION RESPONSE START =====")
    logger.info(f"[FLOW_SESSION_DELETE_RESPONSE_FULL] Session: {session_id}")
    logger.info(f"[FLOW_SESSION_DELETE_RESPONSE_FULL] Status Code: 200")
    logger.info(f"[FLOW_SESSION_DELETE_RESPONSE_FULL] Elapsed Time: {elapsed_time:.3f}s")
    logger.info(f"[FLOW_SESSION_DELETE_RESPONSE_FULL] Response Body: {json.dumps(response_data, ensure_ascii=False, indent=2)}")
    logger.info(f"[FLOW_SESSION_DELETE_RESPONSE_FULL] ===== DELETE SESSION RESPONSE END =====")
    
    return response_data

@router.get("/flow-chat/emotions")
async def get_available_emotions(request: Request):
    """ì‚¬ìš© ê°€ëŠ¥í•œ ê°ì • ëª©ë¡ ì¡°íšŒ"""
    start_time = time.time()
    
    # ìš”ì²­ ë¡œê¹…
    client_ip = request.client.host if request.client else "unknown"
    user_agent = request.headers.get("user-agent", "unknown")
    
    logger.info(f"[FLOW_EMOTIONS_REQUEST] IP: {client_ip}")
    logger.info(f"[FLOW_EMOTIONS_REQUEST_FULL] ===== GET EMOTIONS REQUEST START =====")
    logger.info(f"[FLOW_EMOTIONS_REQUEST_FULL] IP: {client_ip}")
    logger.info(f"[FLOW_EMOTIONS_REQUEST_FULL] User-Agent: {user_agent}")
    logger.info(f"[FLOW_EMOTIONS_REQUEST_FULL] Headers: {dict(request.headers)}")
    logger.info(f"[FLOW_EMOTIONS_REQUEST_FULL] Method: {request.method}")
    logger.info(f"[FLOW_EMOTIONS_REQUEST_FULL] URL: {request.url}")
    logger.info(f"[FLOW_EMOTIONS_REQUEST_FULL] ===== GET EMOTIONS REQUEST END =====")
    
    response_data = {
        "emotions": list(EMOTION_TEACHING_EXPRESSIONS.keys()),
        "teaching_expressions_preview": {
            emotion: [expr["word"] for expr in expressions[:2]] 
            for emotion, expressions in EMOTION_TEACHING_EXPRESSIONS.items()
        }
    }
    
    elapsed_time = time.time() - start_time
    
    # ì‘ë‹µ ë¡œê¹… (ìš”ì•½ + ìƒì„¸)
    logger.info(f"[FLOW_EMOTIONS_RESPONSE] Time: {elapsed_time:.3f}s | Emotions: {len(response_data['emotions'])}")
    logger.info(f"[FLOW_EMOTIONS_RESPONSE_FULL] ===== GET EMOTIONS RESPONSE START =====")
    logger.info(f"[FLOW_EMOTIONS_RESPONSE_FULL] Status Code: 200")
    logger.info(f"[FLOW_EMOTIONS_RESPONSE_FULL] Elapsed Time: {elapsed_time:.3f}s")
    logger.info(f"[FLOW_EMOTIONS_RESPONSE_FULL] Response Body: {json.dumps(response_data, ensure_ascii=False, indent=2)}")
    logger.info(f"[FLOW_EMOTIONS_RESPONSE_FULL] ===== GET EMOTIONS RESPONSE END =====")
    
    return response_data

async def _generate_openai_response_with_tts(session: ConversationSession, stage: ConversationStage, openai_service: OpenAIService, context: str = "") -> tuple[str, Optional[str]]:
    """OpenAIë¡œ ë‹¨ê³„ë³„ ì‘ë‹µ ìƒì„±"""
    
    try:
        # ì–¸ì–´ ì„¤ì • - Mixed language ì‚¬ìš©
        mixed_language = f"Mixed {session.from_lang}-{session.to_lang}"
        emotion_in_ai_lang = session.emotion if session.to_lang == "english" else session.emotion  # ì˜ì–´ ê°ì •ëª… ê·¸ëŒ€ë¡œ ì‚¬ìš©
        
        if stage == ConversationStage.STARTER:
            # ì‹œì‘ ë‹¨ê³„: ê°ì • í‘œí˜„ í•™ìŠµ ì†Œê°œ + ì§ˆë¬¸
            prompt = f"""
            User selected {session.emotion} emotion.
            
            Create response in {mixed_language} (mixing Korean and English naturally):
            1. Introduce learning expressions related to "{emotion_in_ai_lang}" emotion in {session.to_lang}
            2. Ask engaging question like "~í•˜ë©´ {emotion_in_ai_lang}ì„ ëŠë¼ê²Œ ë˜ì£ . ì–˜ê¸°í•´ë³¼ê¹Œìš”?" or "ìµœê·¼ì— {emotion_in_ai_lang}ì„ ëŠë‚€ ì ì´ ìˆë‚˜ìš”?" in {session.from_lang}
            
            2-3 sentences, friendly casual tone. Mix languages naturally.   
            """
            
        elif stage == ConversationStage.FINISHER:
            # ì™„ë£Œ ë‹¨ê³„: ëŒ€í™” ë§ˆë¬´ë¦¬
            learned_words = [expr.word for expr in session.learned_expressions] if session.learned_expressions else []
            prompt = f"""
            Completed {session.user_input_count} conversations about {session.emotion} emotion.
            Learned expressions: {', '.join(learned_words) if learned_words else 'none'}
            
            Say goodbye in {mixed_language}: thanks + encouragement + mention learned expressions.
            2-3 sentences, friendly casual tone. Mix languages naturally.
            """
            
        elif stage == ConversationStage.RESTART:
            # ì¬ì‹œì‘ ë‹¨ê³„: ê°ì • í‘œí˜„ í•™ìŠµ ì†Œê°œ + ì§ˆë¬¸
            prompt = f"""
            Restarting conversation with {session.emotion} emotion.
            
            Create response in {mixed_language} (mixing Korean and English naturally):
            1. Introduce learning expressions related to "{emotion_in_ai_lang}" emotion in English
            2. Ask engaging question like "~í•˜ë©´ {emotion_in_ai_lang}ì„ ëŠë¼ê²Œ ë˜ì£ . ì–˜ê¸°í•´ë³¼ê¹Œìš”?" or "ìµœê·¼ì— {emotion_in_ai_lang}ì„ ëŠë‚€ ì ì´ ìˆë‚˜ìš”?"
            
            2-3 sentences, friendly casual tone. Mix languages naturally.
            """
            
        else:
            # ê¸°íƒ€ ë‹¨ê³„ì˜ ê²½ìš° ì»¨í…ìŠ¤íŠ¸ ì‚¬ìš©
            prompt = f"""
            {session.emotion} emotion context: {context}
            
            Respond with empathy in {mixed_language}. 2-3 sentences, friendly casual tone. Mix languages naturally.
            """
        
        logger.info(f"[FLOW_OPENAI_STAGE_REQUEST] Session: {session.session_id} | Stage: {stage} | Generating response")
        
        response = await openai_service.get_chat_completion(
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7
        )
        
        generated_text = response.choices[0].message.content.strip()
        
        logger.info(f"[FLOW_OPENAI_STAGE_RESPONSE] Session: {session.session_id} | Stage: {stage} | Generated: {generated_text}")
        
        # TTSë¡œ ìŒì„± ë³€í™˜ ë° R2 ì—…ë¡œë“œ (Mixed languageì´ë¯€ë¡œ Korean ê¸°ë³¸ ì‚¬ìš©)
        audio_url = None
        try:
            # Mixed languageì´ë¯€ë¡œ Korean TTS ì‚¬ìš©
            tts_language = "Korean"
            audio_url, duration = await openai_service.text_to_speech(generated_text, tts_language)
            logger.info(f"[FLOW_TTS_SUCCESS] Session: {session.session_id} | Stage: {stage} | Audio URL: {audio_url} | Duration: {duration:.2f}s")
        except Exception as tts_error:
            logger.error(f"[FLOW_TTS_ERROR] Session: {session.session_id} | Stage: {stage} | TTS failed: {str(tts_error)}")
            # TTS ì‹¤íŒ¨í•´ë„ í…ìŠ¤íŠ¸ ì‘ë‹µì€ ë°˜í™˜
        
        return generated_text, audio_url
        
    except Exception as e:
        logger.error(f"[FLOW_OPENAI_STAGE_ERROR] Session: {session.session_id} | Stage: {stage} | Error: {str(e)}")
        
        # Emergency fallback - Mixed language ì‚¬ìš©
        fallback_text = ""
        if stage == ConversationStage.STARTER:
            fallback_text = f"ì•ˆë…•í•˜ì„¸ìš”! {session.emotion} ê°ì •ê³¼ ê´€ë ¨ëœ expressionsë¥¼ ë°°ì›Œë´ìš”. ìµœê·¼ì— {session.emotion}ì„ ëŠë‚€ ì ì´ ìˆì–´ìš”?"
        elif stage == ConversationStage.FINISHER:
            fallback_text = f"{session.emotion} ê°ì •ì— ëŒ€í•´ ì´ì•¼ê¸°í•´ì£¼ì…”ì„œ ê°ì‚¬í•´ìš”. ìƒˆë¡œìš´ expressionsë¥¼ ì˜ ë°°ìš°ì…¨ì–´ìš”!"
        elif stage == ConversationStage.RESTART:
            fallback_text = f"ìƒˆë¡­ê²Œ ì‹œì‘í•´ë´ìš”! {session.emotion}ê³¼ ê´€ë ¨ëœ expressionsë¥¼ ë°°ì›Œë³¼ê¹Œìš”?"
        else:
            fallback_text = f"{session.emotion} ê°ì •ì„ ì´í•´í•´ìš”. ë” ì´ì•¼ê¸°í•´ì£¼ì‹¤ ìˆ˜ ìˆì–´ìš”?"
        
        # í´ë°± ì‘ë‹µì— ëŒ€í•´ì„œë„ TTS ì‹œë„ (Mixed languageì´ë¯€ë¡œ Korean ê¸°ë³¸ ì‚¬ìš©)
        audio_url = None
        try:
            fallback_tts_language = "English"  # Mixed languageëŠ” ì£¼ë¡œ ì˜ì–´ ê¸°ë°˜
            audio_url, duration = await openai_service.text_to_speech(fallback_text, fallback_tts_language)
            logger.info(f"[FLOW_TTS_FALLBACK_SUCCESS] Session: {session.session_id} | Stage: {stage} | Audio URL: {audio_url}")
        except Exception as tts_error:
            logger.error(f"[FLOW_TTS_FALLBACK_ERROR] Session: {session.session_id} | Stage: {stage} | TTS failed: {str(tts_error)}")
        
        return fallback_text, audio_url 